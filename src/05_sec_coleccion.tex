

\section{Recolección de datos}

\begin{table*}[t]
    \centering
    \large
    \begin{tabular}{ l l r }
        Nombre     &  username          & \#Followers \\
        \hline
        La Nación  &  @LANACION         & \num{3.6}M            \\
        Clarín     &  @clarincom        & \num{3.2}M        \\
        Infobae    &  @infobae          & \num{3.0}M   \\
        Perfil     &  @perfilcom        & \num{0.8}M    \\
        Crónica    &  @cronica          & \num{0.8}M     \\
        \hline
    \end{tabular}
    \caption{Cuentas de medios utilizadas para la recolección de datos, junto a sus nombres de usuarios y la cantidad de seguidores en Twitter (al momento de la recolección)}
    \label{tab:medios_analizados}
\end{table*}


En esta sección detallaremos el proceso de recolección de datos, cuya salida es un conjunto de artículos mencionados en Twitter y sus comentarios respectivos realizados por usuarios. Describiremos a continuación las decisiones realizadas respecto a las fuentes y a otros detalles técnicos.

En primer lugar, limitamos nuestra recolección de datos a cuentas de medios de la República Argentina y, puntualmente, nos centramos en diarios con comunidad mayormente rioplatense. Esto lo realizamos teniendo en mente que los anotadores serían nativos de esta variedad dialectal ya que, como mencionamos anteriormente, el discurso de odio contra mujeres, grupos nacionales y otros depende fuertemente de la jerga y de las variaciones dialectales de cada lugar. Esta elección, se debe además a que, habiendo buscando en otros medios de Argentina (como por ejemplo ``La voz del Interior'', diario dirigido mayormente a un público fuera de la Metrópolis de Buenos Aires) observamos que la interacción en Twitter de estos medios es muy baja, con muy pocos usuarios comentando sus notas. Centrándonos en diarios que generen interacción, seleccionamos medios periodísticos de gran llegada y tradicionales, los cuales listamos en la Tabla \ref{tab:medios_analizados}.

Si bien recolectamos notas de otros medios, no los consideraremos a partir de ahora, y los dejamos para análisis posteriores. De los cinco medios elegidos, todos son medios formales y con varios años en el medio, siendo cuatro de ellos con soporte escrito y uno sólo (Infobae) enteramente digital. Consideramos la posibilidad de elegir medios no tradicionales y más orientados a grupos de la ``derecha alternativa'', dada su alta incidencia de contenido de odio. Sin embargo, finalmente tomamos la decisión de descartarlos de la etapa de anotación.


\subsection{Método de recolección}



La API de Twitter, en su versión gratuita, nos brinda dos modos de recolectar tweets de su plataforma\footnote{Usamos la versión 1.1 de la API. La versión 2.0 parece facilitar la recopilación de conversaciones. Recomendamos investigar mejor esta versión actualizada para esquivar muchas de las dificultades técnicas que incursionamos para lo descripto en esta sección}:

\begin{enumerate}
    \item \emph{Search API}: permite buscar tweets en base a términos, de hasta 15 días atrás sobre una pequeña muestra, recreando lo que vemos en la UI de Twitter
    \item \emph{Stream API}: permite buscar tweets en tiempo real sobre una muestra de cerca del 1\% de todos los tweets de la red social
\end{enumerate}

La \emph{Stream API} (también conocida como \emph{Spritzer}), mientras por un lado limita temporalmente la recolección de datos, por el otro nos brinda la posibilidad de recolectar una mayor cantidad de información en tiempo real. Más aún, dada la naturaleza de nuestro problema (discurso de odio), se corre el riesgo de que ciertos tweets con el tiempo sean moderados e inaccesibles para cualquier búsqueda con la \emph{Search API}.

Por lo explicado, usamos la \emph{Stream API} de Twitter, buscando tweets que mencionen a cualquiera de las cuentas de medios periodísticos listadas en la Tabla \ref{tab:medios_analizados}. Si estamos entonces recolectando tweets sobre \verb|@medio|, la \emph{Search API} nos da:

\begin{enumerate}
    \item Tweets de \verb|@medio|
    \item Respuestas a los tweets de \verb|@medio|
    \item Tweets de terceros que mencionan a \verb|@medio|
    \item Retweets (RT) de tweets de \verb|@medio|
    \item Citas de tweets de \verb|@medio|
\end{enumerate}

Los RTs y tweets que simplemente arroben a \verb|@medio| carecen de interés para nuestro estudio, con lo cual los descartamos. Por otro lado, también descartamos las citas, aunque podrían entenderse en algún punto como respuestas a los tweets originales. Nos quedamos finalmente con tweets de \verb|@medio| y las respuestas a estos. Si bien la API nos da estos tweets de manera desestructurada, reconstruimos el árbol de la discusión mediante el campo \verb|in_reply_to_status_id|\footnote{Ver la documentación y la referencia al campo en \url{https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet}}, que marca el tweet al que responde.

Algo importante a remarcar es que, para el propósito de este trabajo, sólo estamos interesados en el primer nivel de respuestas al tweet original, y no incorporamos hilos de respuestas. Trabajo futuro debería explorar este nivel adicional de complejidad incorporando contexto conversacional adicional.

Accidentalmente, la recolección de datos se dio al mismo tiempo del estallido de la pandemia del COVID-19. Dadas las implicancias de la pandemia sobre el discurso discriminatorio en las redes sociales, se volcó el foco de la recolección hacia artículos relacionados con el coronavirus. Para ello seleccionamos artículos buscando la ocurrencia de ciertas palabras en el cuerpo del artículo, específicamente relacionadas al COVID-19: \emph{coronavirus, encierro, síntomas, covid, fase, fiebre, cuarentena, infectados, distanciamiento, normalidad,  Wuhan, aislamiento}.

Por último, nos quedamos con aquellos tweets de los medios periodísticos que tuvieran un link a un artículo. Para ello, utilizamos el módulo de Python \emph{newspaper3k}\footnote{\url{https://newspaper.readthedocs.io/en/latest/}}, que permite acceder a la información relacionada a los artículos en cuestión, en particular siendo lo que más nos interesa el cuerpo del artículo. Aquellos tweets de medios periodísticos que no contengan un link a un artículo fueron descartados por considerar que no representaban una noticia en sí.

\subsection{Datos recolectados}

\begin{table}[t]
    \centering
    \begin{tabular}{l rr}
    Medio      & \#Artículos & \#Comentarios \\
    \thline{2}
    @infobae   &  \num{45652}   &  \num{822462} \\
    @clarincom &  \num{29050}   &  \num{672401} \\
    @perfilcom &   \num{8764}   &   \num{61203}  \\
    @LANACION  &  \num{16040}   &  \num{506091} \\
    @cronica   &  \num{17250}   &   \num{70872} \\
    \hline
    Total      & \num{116756}   & \num{2133029} \\
    \thline{2}
    \end{tabular}
    \caption{Elementos recolectados por cada medio, medidos en cantidad de artículos (tweets de los medios + artículos correspondientes) y cantidad de comentarios (respuestas en Twitter a los primeros)}
    \label{tab:articulos_recoletados_por_medio}
\end{table}


La Tabla \ref{tab:articulos_recoletados_por_medio} contiene la cantidad de artículos recolectados por cada medio, luego de ser aplicado el filtro de palabras mencionado en la anterior sección, y cantidad de comentarios por medio. Si bien recolectamos más artículos de otros medios, no son enumerados, aunque fueron conservados para otros experimentos. Entre los medios seleccionados, Infobae fue el más prolífico en artículos y también será finalmente sobre el que más comentarios etiquetemos. En el apéndice \ref{app:distribucion_datos} puede encontrarse la distribución temporal de los datos. Si bien tenemos un pequeño bache en los datos por un problema técnico en la recolección, los artículos de este conjunto datan de Marzo del 2020 hasta Febrero del 2021.

En la siguiente sección realizaremos un filtrado de la mayoría de estos artículos previamente a la anotación. En conjunto a los datos de otros medios, estos artículos y comentarios no etiquetados son preservados para efectuar ajustes de dominio, y serán liberados como se recomienda en \citet{gururangan-etal-2020-dont}. Hablaremos más sobre esto en los Capítulos \ref{chap:06_contextualized_hate_speech} y \ref{chap:07_domain_adaptation}.

