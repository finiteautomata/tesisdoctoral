
Debemos ser, sin embargo, cautelosos acerca de los resultados obtenidos en este trabajo y, en líneas generales, de la mayoría de los avances en la detección de discurso discriminatorio. El estado del arte actual en NLP está basado en modelos de lenguajes neuronales pre-entrenados. En términos de lo mencionado en \emph{The Book of Why} de Judea Pearl \cite{pearl2018book}, estos sistemas están en una etapa meramente ``asociacional''. Es decir, nuestros actuales sistemas tan sólo detectan regularidades en los datos, como si fueran sólamente el ajuste de una curva que un estadístico realiza hace más de un siglo, sin realizar ningún tipo de razonamiento causal o simbólico.

En nuestro problema concreto, un clasificador puede detectar que decirle ``sos hombre'' a un artículo relacionado a una mujer (quizás trans) conlleva discurso de odio contra la comunidad LGBTI. Sin embargo, este mismo mensaje ofuscado de alguna manera (por ejemplo, preguntándole el nombre, o alguna otra forma que no hayamos observado en los datos) logra burlar a nuestros sistemas.

Ligado a esta reflexión, Bender y Gebru \todo{citation needed} han realizado una serie de trabajos ilustrando este punto: nuestros actuales sistemas, basados en modelos de lenguaje, aún en sus formas más complejas y sobreparametrizadas con miles de millones de parámetros, no son más que ``loros estadísticos'', muy hábiles en detectar regularidades y hacernos creer que llevan adentro algún tipo de razonamiento. Sin embargo, la realidad es que no lo tienen.

¿Significa esto que los sistemas actuales no sirven para nada? En absoluto. Los actuales sistemas, aún con sus defectos y siendo bastante rudimentarios, logran detectar parte del lenguaje discriminatorio que observamos en redes sociales. Sin embargo, es necesario entender sus limitaciones: a medida que estos sistemas puedan encontrar regularidades con más detalle, muchos usuarios ocultarán este discurso de manera más sofisticada para lograr burlarlos (en caso de que estemos hablando de sistemas que se usen con fines de moderación).

- Agregar algo de foundation models
- Why AI is harder than we think, by