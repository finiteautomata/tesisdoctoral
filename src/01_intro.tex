
\section{Discursos de odio}


El discurso discriminatorio  puede describirse como aquel discurso en clave de intenso aborrecimiento, denigración y enemistad que ataca a un individuo o un grupo de individuos por poseer --o aparentar poseer-- cierta característica protegida por tratados internacionales como el sexo, el género, la etnia, etc. Si bien no hay un consenso generalizado sobre qué configura exactamente lenguaje de odio o discriminación\cite{article192015}, un posible punto de contacto entre las distintas definiciones apuntan hacia


En los últimos años, este tipo de discurso ha tomado gran relevancia en redes sociales y otros medios virtuales debido a su intensidad y a su relación con actos violentos contra miembros de estos grupos.

A raíz de esto, estados y organizaciones supranacionales como la Unión Europea han sancionado legislación que insta a las empresas de redes sociales a moderar y eliminar contenido discriminatorio, con particular foco de aquel que insta a la violencia física.

Debido a la enorme cantidad de contenido generado por usuarios en las redes sociales, es necesario contar con cierta automatización en esta tarea bien para su análisis o para su moderación. Desde el procesamiento de lenguaje natural, la detección de discriminación puede entenderse como una clasificación de texto: dado un texto generado por un usuario, predecir si es o no contenido discriminatorio. Así mismo, puede ser de interés predecir otras características: por ejemplo, si el texto contiene un llamado a la acción violenta, si está dirigido contra un individuo o un grupo, el tipo de característica ofendida, entre otras.

Una de las limitaciones de los enfoques actuales para la detección del lenguaje discriminatorio es la falta de contexto en el mensaje. La mayoría de los estudios y recursos están hechos sobre datos fuera de contexto; es decir, mensajes aislados sin ningún tipo de contexto conversacional o del tema del cual se habla. Esto restringe la información disponible –tanto para un humano como para un sistema– para poder discernir si un texto social es discriminatorio. Otra información usualmente faltante es la característica atacada: es común que los datasets estén anotados de manera poco granular, no brindando información acerca de si la agresión es por motivos de sexo, género, clase social, etc. Por último, una limitación puntual del español es la poca disponibilidad de recursos para esta tarea. Más aún, los datasets suelen estar anotados por anotadores que no son hablantes de las variedades dialectales de los textos utilizados, lo cual genera un déficit en su calidad al ser el lenguaje discriminatorio altamente dependiente de la jerga específica de cada región.

En esta tesis pretendemos abordar algunas de las limitaciones marcadas. Por un lado, analizamos el impacto de agregar contexto a la detección de lenguaje discriminatorio en redes sociales. Para ello, construimos un dataset de tweets en base a las respuestas de los usuarios a los posteos de medios periodísticos en Twitter. Esto nos permite obtener dos tipos de contextos: uno “conversacional” al tener una respuesta a un tweet anterior, y uno más extenso al obtener el texto de la noticia en cuestión. El corpus fue recolectado sobre noticias relacionadas a la pandemia del COVID-19, en idioma español mayormente en su variedad dialectal rioplatense y anotado por hablantes nativos de ese dialecto con un modelo de etiquetado granular respecto a las características ofendidas.

Sobre los comentarios de este dataset realizamos experimentos de detección de discurso de odio planteando dos tareas: detección “plana” del lenguaje discriminatorio, donde sólo predecimos una etiqueta binaria indicando presencia de lenguaje discriminatorio; y detección “granular”, donde predecimos las características ofendidas. Usando técnicas del estado del arte, obtuvimos mejoras significativas en ambas tareas al agregar contexto como entrada de cada instancia, tanto en su forma corta (sólo el titular/tweet de la noticia) como en su forma larga (titular + cuerpo de la noticia). Así mismo, observamos que un clasificador entrenado para la tarea “granular” mejora levemente su performance al ser evaluado para la tarea “plana”, obviando los posibles errores de motivos discriminatorios. Combinando la adición de contexto y granularidad, un clasificador para la detección de lenguaje discriminatorio obtiene mejoras considerables sobre un BERT en español que sólo consume el texto del comentario.

Considerando la detección de discurso de odio dentro del área más abarcativa de clasificación de documentos en dominios sociales, analizamos algunos aspectos generales para tareas relacionadas como el análisis de sentimiento y la detección de emociones, entre otras. En particular, analizamos el desempeño de las técnicas de representación al ser entrenadas en distintos dominios. En general, los modelos de representación son entrenados a partir de textos de dominios “formales”, como pueden ser Wikipedia u otras fuentes similares. En esta tesis analizamos el efecto de generar estas representaciones desde textos informales. Observamos que –desde los word embeddings hasta los modelos pre-entrenados basados en transformers– las representaciones generadas son robustas y mejoran la performance en un conjunto de tareas de clasificación en textos sociales. Sobre los modelos pre-entrenados, estudiamos el impacto de entrenarlos desde cero en textos sociales o efectuar una adaptación sobre este dominio

Todos los estudios y recursos de esta tesis fueron realizados en español. Como un objetivo secundario, pretendemos mitigar la enorme asimetría de recursos existente en el área del procesamiento del lenguaje natural.



\subsection{Atentados en Charlottesville}

En Agosto del 2017, una gran movilización organizada por varios movimientos de ultraderecha y supremacistas blancos tuvo lugar en la ciudad de Charlottesville, Virginia, Estados Unidos, y particularmente centrada en la Universidad de dicho Estado. Esta concentración fue llamada en el medio del intento de universitarios y el movimiento Black Lives Matter (BLM) de remover estatuas de militares conferados pro-esclavitud de la Guerra de Secesión; en el caso de la Universidad de Virginia, sobre la estatua de Robert Lee. Más aún, tuvo lugar durante los primeros meses del mandato de Donald Trump.

Numerosos grupos de ultraderecha, neonazis, neo-confederados, entre otros, convocaron a la marcha ``Unite the Right'', diseñada como una campaña militar y organizada hasta 3 meses antes de su concreción. \citet{blout2020white} describen la experiencia de Charlottesville como la de un ``terrorismo inmersivo'', ya que generaron un ámbito de terror en varios ``teatros'' (como lo llaman los autores, usando jerga militar). Principalmente, el teatro físico, con la marcha y enfrentamientos con las contra-movilizaciones, la intimidante marcha de antorchas, y el asesinato de Heather Heyer atropellada por un manifestante neo-nazi. Así mismo, el teatro ``virtual'', que sirvió para generar un clima de intimidación en la previa, durante, y luego del evento, de alguna manera. \citet{blout2020white} citan particularmente una campaña judeófoba contra el mayor de Charlottesville (de ascendencia judía) y el vicemayor (afroamericano).

En el trabajo anteriormente mencionado, los autores llegan a la conclusión de que el evento fue organizado de manera centralizada, tanto en su planificación como despliegue en un intento de ejercicio militar. También concluyen que, la propaganda y la información propagada por los organizadores sirvió para publicitar y reclutar a simpatizantes y también para aterrorizar a la población. Esta propaganda tuvo lugar tanto en medios impresos (por ejemplo, posters pegados en las calles) como por medios virtuales y redes sociales como Facebook, Twitter o Discord. \citet{klein2019twitter} analiza los intercambios en Twitter entre los dos bandos (manifestantes de ultraderecha y los contramanifestantes) y muestra que, en el caso de quienes se encontraban del lado de la marcha de UtR, se identifica como enemigos a los musulmanes, liberales o izquierdistas,a miembros de la comunidad LGBTQ, judíos, entre otros.


\subsection{Matanza en Sinagoga de Pittsburgh}

En Octubre de 2018, un hombre fuertemente armado entró a la sinagoga ``El Árbol de la Vida'' en Pittsburgh, Pensilvania, Estados Unidos. Luego de gritar ``muerte a los judíos'', abrió fuego contra la multitud matando 11 personas y dejando decenas de heridos. El tirador era usuario activo de Gab\footnote{\url{https://gab.com/}}, una red social que nació en 2016 bajo la égida de la ``libertad de expresión'' con motivo de la creciente moderación de Twitter a discursos discriminatorios. El asesino en cuestión posteaba frecuentemente contenido antisemita en dicha red social \cite{mcilroy2019welcome}, la cual ha sido descrita como el ``Twitter racista''.

A raíz de esto, Gab fue dado de baja durante cierto tiempo al serle negado alojamiento web. Desde entonces, diversos trabajos han estudiado y recopilado el contenido discriminatorio en esta red social \cite{mcilroy2019welcome,kennedy2018gab}.


\begin{figure}[htbp]
    \centering
    \includegraphics[height=6cm, keepaspectratio]{img/gab-pittsburgh-post.jpg}
    \caption{Último post de Robert Bowers, tirador en la masacre de Pittsburgh, en la red social Gab.}
    \label{fig:gab_post}
\end{figure}
















\section{Revolución de NLP en los últimos años}
\section{NLP aplicado a redes sociales}

\section{Aportes de este trabajo}

Agrego algunas referencias para ir teniendo en cuenta:

\begin{itemize}
    \item Manifesto of Computational Social Sciences \cite{conte2012manifesto}
    \item Text Analysis in Python for Social Scientists: Discovery and Exploration \cite{hovy2020text} (Leer intro nada más)
    \item Computational social science and sociology (2020): \cite{edelmann2020computational}
\end{itemize}